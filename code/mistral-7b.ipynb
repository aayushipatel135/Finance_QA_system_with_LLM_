{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6233908,"sourceType":"datasetVersion","datasetId":3524554},{"sourceId":6989879,"sourceType":"datasetVersion","datasetId":3953159}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\ndf = pd.read_csv(\"/kaggle/input/finance-mcq-question/finance_MCQ_topic.csv\")\ndf \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-11T13:57:49.349763Z","iopub.execute_input":"2023-11-11T13:57:49.350528Z","iopub.status.idle":"2023-11-11T13:57:49.730731Z","shell.execute_reply.started":"2023-11-11T13:57:49.350501Z","shell.execute_reply":"2023-11-11T13:57:49.729834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/finance-mcq-question/finance_MCQ_topic.csv\")\ndf ","metadata":{"execution":{"iopub.status.busy":"2023-11-07T10:20:42.935962Z","iopub.execute_input":"2023-11-07T10:20:42.936270Z","iopub.status.idle":"2023-11-07T10:20:42.976025Z","shell.execute_reply.started":"2023-11-07T10:20:42.936244Z","shell.execute_reply":"2023-11-07T10:20:42.975141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install -q -U bitsandbytes\n! pip install -q -U git+https://github.com/huggingface/transformers.git \n! pip install -q -U git+https://github.com/huggingface/peft.git\n#pip install -q -U git+https://github.com/huggingface/accelerate.git\n#current version of Accelerate on GitHub breaks QLoRa\n#Using standard pip instead\n! pip install -q -U accelerate\n! pip install -q -U datasets","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:57:49.732404Z","iopub.execute_input":"2023-11-11T13:57:49.732670Z","iopub.status.idle":"2023-11-11T13:59:46.483331Z","shell.execute_reply.started":"2023-11-11T13:57:49.732645Z","shell.execute_reply":"2023-11-11T13:59:46.481856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndata = load_dataset(\"csv\", data_files=\"/kaggle/input/finance-mcq-question/finance_MCQ_topic.csv\")\ndata #= data.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T10:22:20.036543Z","iopub.execute_input":"2023-11-07T10:22:20.036961Z","iopub.status.idle":"2023-11-07T10:22:21.821851Z","shell.execute_reply.started":"2023-11-07T10:22:20.036924Z","shell.execute_reply":"2023-11-07T10:22:21.820955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:59:46.485298Z","iopub.execute_input":"2023-11-11T13:59:46.486278Z","iopub.status.idle":"2023-11-11T13:59:51.115101Z","shell.execute_reply.started":"2023-11-11T13:59:46.486224Z","shell.execute_reply":"2023-11-11T13:59:51.114266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", quantization_config=quant_config, device_map={\"\":0})","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:59:51.117260Z","iopub.execute_input":"2023-11-11T13:59:51.117736Z","iopub.status.idle":"2023-11-11T14:03:16.549197Z","shell.execute_reply.started":"2023-11-11T13:59:51.117709Z","shell.execute_reply":"2023-11-11T14:03:16.548146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_prompt(data_point):\n    return f\"\"\" Examine the given options thoroughly and determine the optimal choice that accurately addresses the following multiple-choice question.\n    ### Question:\n    {data_point['Question']}\n    ### Option A:\n    {data_point['Option A']}\n    ### Option B:\n    {data_point['Option B']}\n    ### Option C:\n    {data_point['Option C']}\n    ### Option D:\n    {data_point['Option D']}\n    ### Correct Ans of the above MCQ question is :\n    {data_point['Answer']}\n    ### Above answer is correct because : \n    {data_point['Explanation']}\"\"\"\n\nmapped_qa_dataset = data.map(lambda samples: tokenizer(generate_prompt(samples)))","metadata":{"execution":{"iopub.status.busy":"2023-11-06T07:09:04.202437Z","iopub.status.idle":"2023-11-06T07:09:04.202772Z","shell.execute_reply.started":"2023-11-06T07:09:04.202603Z","shell.execute_reply":"2023-11-06T07:09:04.202619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n\nmodel = prepare_model_for_kbit_training(model)\n\nconfig = LoraConfig(\n    r=16, \n    lora_alpha=64, \n    target_modules=[\"q_proj\",\"v_proj\"], \n    lora_dropout=0.05, #\n    bias=\"none\", \n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, config)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:03:16.550561Z","iopub.execute_input":"2023-11-11T14:03:16.551433Z","iopub.status.idle":"2023-11-11T14:03:16.767783Z","shell.execute_reply.started":"2023-11-11T14:03:16.551396Z","shell.execute_reply":"2023-11-11T14:03:16.766732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install wandb","metadata":{"execution":{"iopub.status.busy":"2023-11-05T04:57:46.942881Z","iopub.execute_input":"2023-11-05T04:57:46.943756Z","iopub.status.idle":"2023-11-05T04:57:59.230790Z","shell.execute_reply.started":"2023-11-05T04:57:46.943709Z","shell.execute_reply":"2023-11-05T04:57:59.229595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device('cuda:0')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T05:06:35.797527Z","iopub.execute_input":"2023-11-05T05:06:35.798208Z","iopub.status.idle":"2023-11-05T05:06:35.847633Z","shell.execute_reply.started":"2023-11-05T05:06:35.798174Z","shell.execute_reply":"2023-11-05T05:06:35.846527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\n\ntokenizer.pad_token = tokenizer.eos_token\n\ntrainer = transformers.Trainer(\n    model=model,\n    train_dataset=mapped_qa_dataset[\"train\"],\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=8,\n        num_train_epochs=5,\n        warmup_steps=100,RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu\n        max_steps=1000,\n        learning_rate=2e-4,\n        fp16=True,\n        logging_steps=1,\n        output_dir=\"outputs\",\n        optim=\"paged_adamw_8bit\"\n    ),\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T05:06:38.995172Z","iopub.execute_input":"2023-11-05T05:06:38.995580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HUGGING_FACE_USER_NAME = \"aayushi135\"","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:03:16.769092Z","iopub.execute_input":"2023-11-11T14:03:16.769404Z","iopub.status.idle":"2023-11-11T14:03:16.773673Z","shell.execute_reply.started":"2023-11-11T14:03:16.769379Z","shell.execute_reply":"2023-11-11T14:03:16.772736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"mistran7b_fine_tunned_1000\"","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:11:32.920101Z","iopub.execute_input":"2023-11-11T14:11:32.920527Z","iopub.status.idle":"2023-11-11T14:11:32.925523Z","shell.execute_reply.started":"2023-11-11T14:11:32.920496Z","shell.execute_reply":"2023-11-11T14:11:32.924309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:11:40.133799Z","iopub.execute_input":"2023-11-11T14:11:40.134685Z","iopub.status.idle":"2023-11-11T14:11:40.161834Z","shell.execute_reply.started":"2023-11-11T14:11:40.134651Z","shell.execute_reply":"2023-11-11T14:11:40.160987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.push_to_hub(f\"{HUGGING_FACE_USER_NAME}/{model_name}\", use_auth_token=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T09:57:06.085597Z","iopub.execute_input":"2023-11-07T09:57:06.086266Z","iopub.status.idle":"2023-11-07T09:57:08.162511Z","shell.execute_reply.started":"2023-11-07T09:57:06.086230Z","shell.execute_reply":"2023-11-07T09:57:08.161460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig\nfrom transformers import AutoModelForCausalLM\nfrom peft import PeftModel\nimport torch\n\nbase_model_name_or_path = \"mistralai/Mistral-7B-v0.1\"\nrepo_name = f\"{HUGGING_FACE_USER_NAME}/{model_name}\"\n\nconfig = LoraConfig.from_pretrained(repo_name)\n\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    device_map=\"auto\",\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n)\n# Load the LoRA model\ninference_model = PeftModel.from_pretrained(model, repo_name)   # <-- e","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:11:49.213499Z","iopub.execute_input":"2023-11-11T14:11:49.214339Z","iopub.status.idle":"2023-11-11T14:12:52.003909Z","shell.execute_reply.started":"2023-11-11T14:11:49.214307Z","shell.execute_reply":"2023-11-11T14:12:52.003088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from peft import PeftModel, PeftConfig\n# from transformers import AutoModelForCausalLM\n\n# config = PeftConfig.from_pretrained(\"aayushi135/mistran7b_fine_tunned_1000\")\n# model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n# model = PeftModel.from_pretrained(model, \"aayushi135/mistran7b_fine_tunned_1000\")","metadata":{"execution":{"iopub.status.busy":"2023-11-07T10:26:58.381549Z","iopub.execute_input":"2023-11-07T10:26:58.382288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:12:52.005478Z","iopub.execute_input":"2023-11-11T14:12:52.005774Z","iopub.status.idle":"2023-11-11T14:12:52.169859Z","shell.execute_reply.started":"2023-11-11T14:12:52.005749Z","shell.execute_reply":"2023-11-11T14:12:52.169058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_inference(data_point):\n    batch = tokenizer(f\"\"\"\n    ### Question:\n    {data_point['Questions']}\n    ### Option A:\n    {data_point['Option A']}\n    ### Option B:\n    {data_point['Option B']}\n    ### Option C:\n    {data_point['Option C']}\n    ### Option D:\n    {data_point['Option D']}\n    ### Correct Ans:\"\"\", return_tensors='pt')\n    with torch.cuda.amp.autocast():\n        output_tokens = inference_model.generate(**batch, max_new_tokens=200)\n    print((tokenizer.decode(output_tokens[0], skip_special_tokens=True)))\n    #display(Markdown((tokenizer.decode(output_tokens[0], skip_special_tokens=True))))","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:12:52.170910Z","iopub.execute_input":"2023-11-11T14:12:52.171180Z","iopub.status.idle":"2023-11-11T14:12:52.177736Z","shell.execute_reply.started":"2023-11-11T14:12:52.171156Z","shell.execute_reply":"2023-11-11T14:12:52.176660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/finance/CA_exam.csv\")\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:12:52.180089Z","iopub.execute_input":"2023-11-11T14:12:52.180397Z","iopub.status.idle":"2023-11-11T14:12:52.238585Z","shell.execute_reply.started":"2023-11-11T14:12:52.180369Z","shell.execute_reply":"2023-11-11T14:12:52.237711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = []\nfor i in range(0,len(df1))  :\n  print(i)\n  l.append(make_inference(df1.iloc[i,:]))","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:12:52.239787Z","iopub.execute_input":"2023-11-11T14:12:52.240103Z","iopub.status.idle":"2023-11-11T17:29:54.458735Z","shell.execute_reply.started":"2023-11-11T14:12:52.240078Z","shell.execute_reply":"2023-11-11T17:29:54.457654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}